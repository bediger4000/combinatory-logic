1. Signal handler
	- done
2. Timer
	- done
3. Optionally, step through reductions, quitting on appropriate input
	- done
3a. Optionally, print out whole tree after every reduction
	- done
4. add "define" and associated storage and cleanup
	- done
5. Make a CL expression into lambda term.
6. Make lambda calculator that compiles into CL, runs it using
   graph reduction, then converts back.
7. Make it "autotool-able".
	- not doing this.
8. Convert back to explicit free-ing of nodes.
	- Doesn't help.  Maximum graph size exists after the
	parse finished.  reduce_graph() never calls new_combinator()
	or new_application().
	- Did help after all: some application nodes do get created,
	as the old ones have to stay in place until ref count drops
	to zero.

Sun Aug 13 11:52:34 MDT 2006

PROGRAM
1. Add signal handler
	- done
2. Add time reduction command to interpreter
	- done
3. Add "define" and associated storage and cleanup
	- 2006-08-14
4. Create ackermann or addition or something, and do some timings
	- 2006-09-18
5. Implement some of Koopman's TIGRE-style optimizations.
	(a) non-recursive reduce_graph()
		- initial version, 2006-10-23
	(b) lexer knows which combinator it finds - parser throws this away.
		- done
6. Compare before and after timings.


Mon Sep 11 22:28:18 MDT 2006

To Do
a) Load file(s) from command line (as lc does)
	done Sat Sep 16 13:47:19 MDT 2006
	- also via "load" interpreter command
b) Add ability to turn off C, B, I combinators on cmomand line
	-- Done 2006-11-20, S, K, I, B, C, W all can get turned off
c) Add W combinator, and ability to turn it off
	-- Done 2006-11-20
d) Single step reductions via interpreter command (on/off)
		-- via command line flag, 11/2006
		-- interpreter command, 2006-11-08
d.1) Use longjmp to get out of single-stepping and back to main
	read-reduce-print loop, also add a "quit interpreter" variant.
		-- done 2006-11-21
e) Add "reduce" interpreter keyword to get reduced expressions
   into environment (analogous to lc's "normalize")
		-- done 2006-09-15
f) Add "delete" interpreter command to remove expressions
   from environment (add to lc as well?).
	- have to add delete to "big" hashtable implementation.
g) Add ability to convert CL expression to a lambda term
h) Add "lccl" algorithms to lc
		-- Also, see item (t) below.
i) Add ability to save dotty-format graph of CL expression
	This should do dashed-lines to show reference counts
j) Add ability to save whole environment to text file
	(add to lc as well?)
k) Better garbage collection of used combinators and
   application nodes via reference counting.
	-- need to add some kind of memory use stats printout
		to tell if this had an effect or not.
			-- done 2006-11-15 or thereabouts
	-- Done 2006-11-10
	-- May not actually collect as aggressively as possible,
		need to step through a complicated reduction to see if
		every unused application & combinator gets dereferenced.
l) Add combinator(s) for some other weird basis.
	- JB Rosser's I and J?
	- single-combinator basis?
m) Make a random CL-expression generator (python?)
	based on BNF grammar.  Use it to make some test cases.
		- Done, 2006-10-28, but in Perl.  See file "evil.expressions"
		for CL expressions that cause problems.
n) Count number of reductions (by combinator?) to check
	the "lazy" evaluation.  See also item (s) below.
o) change lexer to just eat "\\n" so that it looks like
	whitespace and allows multi-line expressions.
	-- done Thu Sep 21 13:57:10 MDT 2006, needs test case(s)
p) Add "prompting", also to lc
	- use command line flag to turn it off, for testing.
	- 2007-04-22, done
q) all command-line flags should have "interpreter command"
	counterparts.
r) spine stack - push-a-node (PUSHNODE macro right now) should
	maybe check stack->stack's depth to avoid array overruns.
	This might constitute a big performance hit, though.
		-- Done 2006-11-15 or so.  Still need to check if performance hit.
		-- see item (u) below.
s) Add a max number of reductions (cmd line flag) to prevent getting
	stuck evaluating terms with no normal form.
		-- also see item (n) above
t) Add variety of bracket abstraction algorithms to cl
	-- 2006-11-21, Curry-Feys simple algorithm
	-- 2006-11-27, Turner algorithm
	- Need to add John Tromp's 9-rule algorithm
		-- 2007-02-02 done
	- Need to add the old BCKW algorithm
		-- 2007-02-28 done
	- Need to add test cases
		-- 2007-02 done
u) Might need to put a limit (changeable from cmd line?) on the max
	spine stack stack size that it can allocate.  Probably need to use
	the longjmp mechanism to quit out of the reduction at that point.
v) Need to write (X)HTML-format document to describe the whole thing,
	especially the reference-counting and arena memory allocation.
	- Perhaps use txt2tags to do this?

w) Add timeout-handling to bracket abstraction.  Also need to clean
	up the grammar around bracket abstraction: too many productions
	exist, when only one should appear.  Have to handle zero-length
	"type" of bracket abstraction ("turner", "curry", "tromp" or ""),
	and select the bracket abstraction function based on the "type".
	This simplifies the addition of timeout-handling.  Also need
	to check memory leaks in this case.
		-- 2007-02-28, done.

x) Add a "timer on"/"timer off" thing: this would let you pick up the
	total time spent between commands, a "summary" of an entire operation.
	The current bracket abstraction timing (item w) gives N values for
	N variables abstracted.

y) Add in Bison-specific flex/bison error handling and output.
	This will aid in diagnosing syntax errors by users (if any).

Could have non-ref counted leaf structs node: the free_node() and
new_combinator() functions could look up leaf nodes in a hash table,
even a simple one, as almost no expression has more than about 10
names for nodes.  Don't bother decrementing ref count on leaf nodes,
as not many of them exist, and they don't "churn" like application
(interior) nodes.

